[TOC]

# OSTEP

## 第一部分 虚拟化

### 第 4 章 抽象：进程

1. 理解进程的关键在于理解它的**机器状态（state machine）**，即程序在运行时可以读取或更新的内容。
   * 内存：程序的指令是存放在内存中的，进程读取和写入的数据也在内存中。进程可以访问的内存称为**地址空间（address space）。**
   * 寄存器：PC指针，栈基址 rbp，栈顶指针 rsp
   * 磁盘：程序可能会修改磁盘中的内容，比如当前程序打开的文件。
2. 进程api：操作系统是对硬件的抽象，同时在应用视角应该是给应用程序提供服务，也就是 api，所以显然操作系统中应该有一组处理进程的 api：
   * 创建进程(create)：创建一个新的进程。
   * 销毁进程(destroy)：如果进程不能正常退出，应当可以关闭。
   * 等待进程(wait)：有的时候进程之间需要同步，所以可能需要某一个进程等待另一个进程完成。
   * 其他控制(miscellanous control)：比如可能将某个进程暂时挂起，然后再恢复。
   * 状态(statu)：获取当前进程的相关信息，比如占用了多少内存。
3. 进程创建的步骤：
   * 程序的指令和数据只有在内存中才可以执行，而程序就是一个存放在磁盘上的文件，所以**首先一定要先将程序从磁盘加载到内存中**。
   * 为程序的运行时栈分配内存。
   * 为程序的堆分配一些内存。
   * 其他初始化任务，比如打开进程的文件描述符，将0 1 2绑定到标准输入、标准输出、标准错误输出。
   * 启动程序，将 CPU 的控制权转移到新创建的进程中去。
4. 进程的状态：
   * 运行：正在占用 CPU
   * 就绪：等待调度，可以去 CPU 上执行指令
   * 阻塞：因为某些原因需要等待某些操作完成，比如 I / O，此时不需要 CPU ，所以让 CPU 调度其他程序，从而提高效率。

### 第 5 章 插叙：进程API

1. * `fork`
   * `execve`
   * `waitpid`
   * `_exit`

### 第 6 章 机制：受限直接执行

1. 通过对 `CPU` 进行时分共享来实现虚拟化，即运行一个进程一段时间以后切换为另一个进程进行运行。要实现这样的机制有如下挑战：

   * 不增加系统开销，实现高性能
   * 对 `CPU` 的控制权，操作系统对资源进行管理，所以理应具有资源的控制权

2. 为了保证性能，所以采用**直接执行**的方式，就是将进程直接放在物理 `CPU` 上进行程序执行，这样的优势是**快速**，但是进程肯定要进行相关的其他操作，比如I/O，这些操作应当是有限制的，换句话说，应当由操作系统来进行管理，比如进程能否访问这个文件，所以硬件通过提供不同的执行模式来协助操作系统。

   * 用户模式：应用程序不能完全访问硬件资源。
   * 内核模式：操作系统可以访问机器的全部资源，并且提供陷入内核和从陷阱返回到用户模式程序的方式。

   当用户希望执行特权操作时，我们可以使用**系统调用**，他允许内核向用户程序暴露某些关键功能。要执行系统调用，程序必须执行特殊的陷阱（trap）指令，该指令跳入内核同时将特权级别提升到内核模式。执行完毕后，操作系统调用一个特殊的从陷阱返回（return-from-trap）指令，该指令返回到发起调用的用户程序中，同时将特权级别降低，回到用户模式。

3. 内核通过在启动时设置陷阱表（trap table）来实现陷阱指令的跳转，即告诉硬件在发生某些异常事件时要运行哪些代码。一旦硬件被通知，它就会记住这些处理程序的位置，直到下一次重新启动机器，并且硬件知道在发生系统调用和其他异常事件时要做什么（即跳转到哪段代码）。
4. 为了进行进程切换，操作系统一定要获取 `CPU` 的控制权，也就是说必须在 `CPU` 上执行操作系统的代码，但是此时用户的进程正在执行，所以有以下机制来达到目标：
   * 协作方式：等待系统调用，进程执行系统调用时，将 `CPU` 的控制权交给操作系统。或者应用程序执行某些非法操作。（死循环，不调用系统调用怎么办？
   * 非协作方式：操作系统进行控制，利用时钟中断使得操作系统重新获取 `CPU` 的控制权。（中断向量表，在启动时告诉硬件哪些代码在发生时钟中断时运行）
5. 无论以哪一种方式，当操作系统获得 `CPU` 的控制权时，将使用调度程序来决定运行哪一个进程，如果决定进行切换，操作系统就会进行**上下文切换**，即为当前正在执行的进程保存一些寄存器的值到内核栈，并为即将执行的进程恢复一些寄存器的值（从它的内核栈）。
6. 中断处理执行程序在执行时、或者系统调用执行时发生了中断怎么办？操作系统应该设计类似的机制来进行处理，即**并发**模块。

### 第 7 章 进程调度：介绍

1. 要思考的关键问题：
   * 如何开发一个考虑调度策略的基本框架？
   * 有哪些关键假设？
   * 哪些指标非常重要？
   * 哪些基本方法已经在早期的系统中使用？
2. 调度指标：
   * 周转时间：$$T_{周转时间} = T_{完成时间} - T_{到达时间}$$
   * 响应时间：$$T_{响应时间} = T_{首次运行} - T_{到达时间}$$
   * 公平性：是否每一个进程在调度的过程中被公平对待。
3. 调度算法：
   * `FIFO`：可能会出现护航效应，一些好事较少的潜在资源消费者被排在重量级的资源消费者之后。即前面的任务需要很长时间才能执行完毕，从而导致整体的周转时间变多。
   * `SJF` ：先运行最短的任务，然后是次短的任务，如此下去。但是任务肯定不会同时到达，而是随即到达，该策略不允许抢占，那么也会出现护航效应。
   * `STCF`：最短完成时间优先，即向 `SJF` 添加抢占。
   * `RR` ：轮转调度，在一个时间片内运行一个工作，然后切换到运行队列中的下一个任务。时间片长度必须是**时钟中断周期的倍数**。

### 第 8 章 调度：多级反馈队列

1. 实际上，我们对于进程的执行时间一无所知，所以我们需要在没有工作长度的先验知识的前提下，设计一个能同时减少响应时间和周转时间的调度程序。**所以我们要从历史中学习，利用历史去预测未来**。计算机系统中还有很多地方是这样的思想，比如硬件的分支预测，缓存算法等。
2. MLFQ调度算法中存在很多队列，每个队列有不同的优先级，同一时间一个工作只能存在于一个优先级队列中，它的基本规则：

   * 运行优先级较高的队列中的工作
   * 同一优先级队列中的工作，使用轮转的方式进行运行

   所以该调度算法的关键在于优先级的确定，它采用一种从历史学习的方法，比如如果一个进程不断的放弃CPU去等待键盘输入，那么该进程可能会是一个交互程序，需要响应时间，所以其优先级较高；如果一个进程一直占用CPU而没有其他操作，那可能它的优先级就会很低。

3. 由于是从历史过程去预测未来，所以我们一定要有某些机制，如：

   * 改变一个进程的优先级：我们使用的策略是当一个进程加入时，总是在优先级最高的队列，如果它的时间片用完，则进入下一个低优先级的队列，如果在它的时间片用完之前主动放弃CPU（可能是一个交互性工作，保证响应时间），则使他的优先级保持不变。（如果采用这样的策略，低优先级队列中的进程可能永远得不到执行；还有一些程序愚弄调度程序，使用99%时间片以后主动释放CPU从而使得自己一直在一个较高的优先级）
   * 为了解决**饥饿**问题，我们可以周期性提升所有工作的优先级，即经过一段时间以后，就将系统中的所有工作都加入到高优先级队列，该策略的关键就在于周期性时间的确认，确认一个合适的时间十分重要。
   * 为了避免愚弄调度程序，可以使用一个更好的计时方式，我们给每一个优先级队列中的进程都分配固定的时间配额，一旦用完了该时间配额，不管主动放弃了多少次，都将其加入到一个低优先级队列中。

### 第 9 章 调度：比例份额

1. 基本思想是：调度程序的最终目标是确保每一个工作可以获得一定比例的CPU时间，而不是优化周转时间和响应时间。所以关键在于如何设计调度程序来按照比例分配CPU。
2. 彩票调度：比如两个进程A和B，A拥有75张彩票，B拥有25张彩票，那么我们就希望A占75%的CPU时间，B占25%的CPU时间，我们通过产生一个1-100的随机数，如果随机数在1-75运行A否则运行B来做到这一点。
3. 步长调度：根据每个工作所占的份额来求取一个步长，再对于每一个工作记录它们的行程值，每次选择最小的行程值进程，然后进行执行，执行完加上一个它自己的步长。

### 第 10 章 多处理器调度（高级）

1. 缓存一致性：每个CPU都有自己的缓存，如果一个CPU上的进程更新了数据还没有写入内存，而另一个CPU上的进程就进行读取就会出现缓存不一致问题。**硬件提供了这个问题的基本解决方案，通过监控内存访问，硬件可以保证获得正确的数据，并保证共享内存的唯一性**。比如在基于总线的系统中，一种方式是使用总线窥探（bus snooping）。每个缓存都通过监听链接所有缓存和内存的总线，来发现内存访问。如果CPU发现对它放在缓存中的数据的更新，会作废（invalidate）本地副本（从缓存中移除），或更新（update）它（修改为新值）。
2. 同步：跨CPU访问，尤其是写入共享数据或数据结构时，需要使用互斥原语来保证正确性，比如锁。
3. 缓存亲和度：一个进程在CPU上运行会缓存一些数据，如果下次还在这个CPU上就会执行的很快，如果在其他的CPU上就执行的很慢。
4. 两种基本模式：
   * 单队列调度：将所有的进程放在一个队列中，然后依次放入不同的CPU中进行执行。这种方式对于共享资源的访问（队列）会出现竞争，可扩展性较差，且每个任务在哪个CPU 上执行是随机的，缓存亲和度较差。
   * 多队列调度：每一个CPU都有一个自己的调度队列，然后将这个调度队列中的任务放在对应的CPU上进行执行。可扩展性较好，缓存亲和度好，但是容易出现负载不均衡，比如某个CPU上的任务执行完毕了，那么这个CPU上就没有任务在执行，浪费了资源，可以使用**任务窃取**来从其他队列中把一些任务移动到该队列来避免该问题，但是什么时候去观察其他队列中的任务情况需要进行斟酌。
5. Linux多处理器调度程序：
   * O(1)调度程序：多队列调度，每个CPU维护140个优先级队列，每个队列对应一个优先级。（MLFQ，多级队列反馈）
   * 完全公平调度程序（CFS）：使用红黑树和虚拟运行时间跟踪，所有可运行任务按照虚拟运行时间排序插入红黑树，调度器始终选择虚拟运行时间最小的任务。（比例份额，步长调度）
   * BFS调度程序（BFS）：所有CPU使用一个全局任务队列，任务按照优先级插入队列，调度器选择最高优先级的任务分配给空闲CPU。

### 第 13 章 抽象：地址空间

1. 地址空间（address space）：是运行的程序看到的系统中内容，是对物理内存的抽象。一个进程的地址空间包含运行的程序的所有内存状态，比如程序的代码、栈（保存函数调用信息、分配空间给局部变量、传递参数和函数返回值）、堆（管理动态分配的、用户管理的内存）、其他（静态初始化的变量）。
2. 虚拟内存系统的目标：
   * 透明：让运行的程序看不见虚拟内存系统的存在。
   * 效率：在空间和时间上尽可能高效。
   * 保护：确保进程受到保护，不会被其他进程影响。

### 第 14 章 插叙：内存操作API

1. 在运行一个 C 程序的时候，会有两种内存类型的分配：
   * 栈：申请和释放由编译器进行管理。
   * 堆：由程序员进行显式的分配和回收。
2. `malloc` 调用：传入要申请的堆空间的大小，成功就返回一个指向新申请空间的指针，失败就返回`NULL`。
3. `free` 调用：接受一个由 `malloc` 返回的指针，不需要分配区域的大小，**必须由内存分配库本身记录追踪**。
4. 常见错误：
   * 忘记分配内存，即使用的指针并没有指向一块动态分配的内存区域。
   * 没有分配足够的内存。
   * 忘记初始化分配的内存。
   * 忘记释放内存
   * 在用完之前释放内存
   * 重复释放内存
   * 错误的调用 `free`，即给 `free` 传入的参数不是一个 `malloc` 得到的指针。
5. 系统中实际存在两级内存管理：
   * 第一级由操作系统执行的内存管理，操作系统在进程运行时将内存交给进程，并在进程退出时将其回收。
   * 第二级管理在每个进程中，例如调用 `malloc()` 和 `free()` ，在堆内管理内存。
6. 管理内存的工具：`purify`  `valgrind`。

### 第 15 章 机制：地址转换

1. 基于硬件的地址转换，动态重定位，基址加界限机制：每个 `CPU` 需要两个硬件寄存器，**基址寄存器**和**界限寄存器**，使用这种方式，编写和编译程序时假设地址空间从零开始，但是当程序真正运行时，操作系统会决定其在物理内存中的实际加载地址，并将起始地址记录在基址寄存器中。

   > physical address = virtual address(address in program) + base

   界限寄存器确保这个地址在进程地址空间的范围内，从而来确保安全。

2. 操作系统必须记录哪些空闲内存没有使用，以便能够为进程分配内存，有许多数据结构可以用于这项任务，比如**空闲列表（free list）。**

3. 采用动态重定位技术，很容易产生内部碎片，即已经分配的内存单元内部有未使用的空间（即碎片）。（因为此时假设地址空间放在固定大小的槽块中）。

### 第 16 章 分段

1. 我们之间假设将所有进程的地址空间完整加载到内存中去，然后通过简单的基址、界限寄存器来进行地址重定位，这样就造成了物理内存空间的浪费，因为堆与栈之间有大量的一些空闲内存，而这些内存无法被其他进程进行使用，造成了浪费。所以采用**分段**的思想，在典型的地址空间里有3个逻辑不同的段：**代码、栈、堆**。我们可以将进程逻辑不同的段放入不同的物理内存段，从而避免栈与堆之间浪费大量的内存空间，所以MMU里面则需要3对基址、界限寄存器。

2. 硬件在进行地址转换的时候，如何知道该地址属于哪个段？如何知道段内的偏移？

   * 显式方式：利用虚拟地址的开头来标识不同的段
   * 隐式方式：通过地址产生的方式来判断，比如，如果地址由程序计数器产生，那么地址在代码段，如果基于栈或基址指针，则在栈段，否则在堆段。

3. 当使用分段的方式进行重定位的时候，会出现一些**外部碎片**，分配的内存之间的有一些很小的内存空间没有得到使用，比如系统现在想分配一个20kb的段，系统的内存空间加起来有24kb，但是因为不连续，所以无法进行内存分配，所以可以有以下解决方案：

   * 紧凑物理内存：重新安排原有的段，让已分配的物理内存紧凑起来，但是该操作是内存密集型任务，会占用大量的处理器时间。
   * 利用空闲列表管理算法，试图保留大得的内存块用于后续的分配，但是算法只能减少，不能避免。

4. 分段机制总结：
   好处：

   * 更高效的虚拟内存，避免了内部碎片。
   * 代码共享，可以给一些段加上控制权限，从而来实现共享。

   坏处：

   * 外部碎片
   * 还是无法解决稀疏地址空间，比如有一个很大但是很稀疏的堆，它们在同一个逻辑段里面，整个堆还是必须完整的加载到内存中。

### 第 17 章 空闲空间管理

1. 当需要管理的空间被划分为固定大小的单元，就很容易进行管理，但是如果要管理的空闲空间由大小不同的单元构成，管理就变得困难，主要要考虑以下问题：
   * 要满足变长的分配请求，应该如何管理空闲空间？
   * 什么策略可以让碎片最小化？
   * 不同方法的时间、空间开销如何？

2. 要提供的机制：
   * 分割：当用户申请的字节数小于空闲列表的长度时，要将该空闲列表进行分割，一部分返回给用户，一部分留着等待后续使用。
   * 合并：当用户归还内存的时候，不应该只是简单的将该内存加入到空闲列表中，而应当与相邻的内存块进行合并。
   * 追踪已分配空间的大小：在 `free` 函数中并没有传入大小，所以内存分配库要能确定要释放空间的大小，从而将其放回空闲列表。大多数分配程序会在头块中保存一点额外的信息，比如用户要20字节的内存，则会先在内存区域存放相关的数据结构，再将该内存后面的20字节返回给用户，释放的时候则可以通过前面的头块数据来读取相关长度。（做实验发现glibc中malloc中要求8字节对齐，最小分配24个字节，可以使用malloc_usable_size()函数返回实际分配的空间大小，而分配的内存前面16个字节则是头块数据结构，两个size_t类型，因为要求8字节对齐，所以分配的长度肯定是8的倍数，且不少于24个字节，所以64位的最低4位用作标志位）。
   * 嵌入空闲列表：在典型的列表实现中，我们使用 `molloc` 来分配一个节点所需要的内存空间，但是当我们使用一个空闲列表来管理 `malloc` 分配的内存时，则需要在空闲空间本身建立空闲空间列表，通过 `mmap` 系统调用来实现，该系统调用返回一个指针，指向一块空闲内存。
   * 让堆增长：大多数传统的分配程序会在堆空间不足时，向操作系统申请更大的空间，使用 `sbrk` 系统调用，会找到空闲的物理内存页，将他们映射到进程的地址空间中，并返回新的堆的末尾地址，从而增长堆空间的大小。

3. 管理空闲空间的基本策略：

   * 最优匹配：遍历空闲列表，分配大于等于用户要求空间大小的最小空闲内存。
   * 最差匹配：找到最大的空闲块，分割并且满足用户要求的空间大小以后，将剩余的块加入空闲列表。
   * 首次匹配：遍历空闲列表，分配第一个满足用户要求的内存块给用户。
   * 下次匹配：在首次匹配的基础上，维护一个额外的指针，记录上次分配的位置，然后下次分配时从该位置进行遍历。

4. 《Understanding glibc malloc》
   1. `brk` 



### 第18章 分页：介绍
1. 解决空间管理问题：
   * 将空间分割成不同长度的分片，分段。
   * 将空间分割成固定长度的分片，分页。
2. 对于每一个进程，操作系统都需要去记录该进程的每一个虚拟页存放在物理内存中的位置，所以操作系统为每一个进程设计了一个数据结构，称为页表（page table）。页表的作用就是保存虚拟页面与物理页面之间的转化关系，也就是一个虚拟页对应的是哪一个物理页。
3. 虚拟地址：虚拟页面号（virtual page number, VPN）和页内偏移（offset，页的大小即确定偏移的位数）
4. 页表的组织：页表就是一种数据结构，用于将虚拟地址映射到物理地址，比如可以是一个数组，os通过虚拟页号VPN检索数组，找到页表项pte（page table entry），然后再找到对应的物理帧号。除了这个简单的对应关系以外，页表项中还包含：
   * 有效位（valid bit）：用于标记地址转换是否有效，os并不会刚开始就给每个虚拟内存分配一个物理页面，而是可以将一些页面标记为无效，这样等os访问的时候，就会进入os代码，去判断访问是否合法，再去进行内存的分配或者 `segmentation fault`。
   * 保护位（protection bit）：用于标记页面是否可以读取、写入、执行。
   * 存在位（present bit）：用于标记该页面是在物理存储器还是在磁盘上，即这一页面是否已经换出（swapped out），从内存换到磁盘。
   * 脏位（dirty bit）：表明该页被带入内存以后是否进行过修改，用于实现一致性。
   * 参考位（reference bit）：用于追踪页是否被访问，用于确定哪些页受欢迎，因此应该保存在内存中。
5. 要进行地址转换，硬件必须知道当前正在运行的进程的页表的位置。


### 第19章 分页：快速地址转换（TLB）
1. 使用分页机制来实现虚拟内存，就需要将地址空间切分成大量固定大小的单元，并且需要记录这些单元的映射信息，而且这些映射信息一般存储在物理内存中，所以在进行虚拟地址转换的时候，分页逻辑上需要一次额外的内存访问。（去内存空间读取到映射关系，然后再进行内存访问。）
2. 为了加快内存访问，os则需要**硬件**的帮助，即地址转换旁路缓冲存储器（translation-lookaside buffer,TLB），频繁发生的虚拟地址到物理地址转换的硬件缓存。对于每次内存访问，硬件先检查TLB，如果有期望的映射，则不再需要去访问页表。
3. 缓存是计算机系统中提升性能的一个常见手段，其基本思路是利用程序的时间局部性和空间局部性原理。但是当 `TLB` 没有命中的时候，必须有一个东西来处理这种情况，很显然，有以下两种选择：

   * 硬件：一般是 cisc 体系架构计算机，有更复杂的指令集。
   * 操作系统：risc 体系架构，当 `TLB` 未命中的时候，硬件系统抛出异常，操作系统暂停当前的执行流，提升至内核模式，跳转至对应的陷阱处理程序，也就是说，处理未命中的代码是一段 `os` 代码。
4. 当利用操作系统处理 `TLB` 未命中的时候，有以下细节需要注意：

   * 不同于一般的系统调用，当从陷阱处理程序返回以后，执行陷入操作系统之后的那条指令，但是 `TLB` 未命中从系统调用返回以后，应当重复执行刚才未命中的那条指令，所以在陷入 `os` 内核的时候，要根据情况保存不同的 `pc`。
   * 要避免无限递归，即陷阱处理程序中也会 `TLB` 未命中。要解决这一问题，可以把陷阱处理程序直接放在物理内存中去，或者在 `TLB` 中保留一些项，记录永远的地址转换，并且将一些项留给陷阱处理程序本身的代码块。
5. `TLB` 中包含的虚拟到物理地址的映射只对当前进程有效，对其他进程是没有意义的。**在上下文切换时，操作系统必须改变页表基址寄存器（PTBR）的值。`PTBR` 中存放的是当前进程页表的物理地址。**


### 第20章 分页：较小的表
1. 假设32位地址空间，每个页大小为 4 KB，那么一共有 $2^{32} / 2^{12} = 2^{20} $ 个页表项，每一个页表项为 4 个字节，那么页表就要占 $2 ^ {20} \times 4 = 2 ^ {22} = 4 MB$，这对于内存空间负担太大，所以我们需要一些方法来使得页表的空间变小。一种方法就是缩小页表项的大小，一种方法就是减少页表项的数量，这是两种基本思路。
   * 更大的页：通过增加每个页的大小，在地址空间保持不变的情况下，就可以减少页表项的数量。但是这种方法会造成页内的浪费，因为将某个页加载到内存的时候，可能只使用一小部分。（内存页太大）
   * 分页和分段：我们将内存分为代码、堆、栈，然后在每个段中再进行分页，使用基址寄存器指向保存该段的页表的物理地址，界限寄存器用于指示页表的结尾。这种方法的主要思路在于减少内存中无效的页表，**我们不是为进程的整个地址空间提供单个页表，而是为每个逻辑分段提供一个。**
   * 多级页表：与分页和分段方法思路一样，即**去掉页表中的所有无效区域，而不是将他们都全部保留在内存中**。将页表分成页大小的单元，如果整页的页表项（PTE）无效，就不分配该页的页表。使用页目录来记录。
2. 超越二级页表：
假设地址空间30位，每一页大小是512个字节，也就是说页内偏移需要9位，页号一共则有21位，**构建多级页表的目标是为了让页表的每一部分都放入一个页，这样子就可以通过页目录项来进行索引。**我们假设每个页表项位4个字节，也就是说一页中可以放入128个页表项，那么我们索引页表的时候就需要 7 位（页表的页内偏移），此时还有14（30 - 9 - 7 = 14）位可以用来索引页表，也就是存放页目录项的表，我们的页目录项就一共有 2 ^ 14 个，也就是页目录项要占用 2 ^ 14 * 4 / 512 = 2 ^ 7 = 128 个页，还是很占用内存空间，所以可以再建立一级页表。
```
cpp
1    VPN = (VirtualAddress & VPN_MASK) >> SHIFT
2    (Success, TlbEntry) = TLB_Lookup(VPN)
3    if (Success == True)    // TLB Hit
4        if (CanAccess(TlbEntry.ProtectBits) == True)
5            Offset   = VirtualAddress & OFFSET_MASK
6            PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
7            Register = AccessMemory(PhysAddr)
8        else
9            RaiseException(PROTECTION_FAULT)
10   else                  // TLB Miss
11       // first, get page directory entry
12       PDIndex = (VPN & PD_MASK) >> PD_SHIFT
13       PDEAddr = PDBR + (PDIndex * sizeof(PDE))
14       PDE     = AccessMemory(PDEAddr)
15       if (PDE.Valid == False)
16           RaiseException(SEGMENTATION_FAULT)
17       else
18           // PDE is valid: now fetch PTE from page table
19           PTIndex = (VPN & PT_MASK) >> PT_SHIFT
20           PTEAddr = (PDE.PFN << SHIFT) + (PTIndex * sizeof(PTE))
21           PTE     = AccessMemory(PTEAddr)
22           if (PTE.Valid == False)
23               RaiseException(SEGMENTATION_FAULT)
24           else if (CanAccess(PTE.ProtectBits) == False)
25               RaiseException(PROTECTION_FAULT)
26           else
27               TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
28               RetryInstruction()
```

### 第 21 章 超越物理内存：机制
1. 为什么要超越物理内存，给进程支持巨大的地址空间？
   * 方便和易用性：程序员只需要自然的编写程序，根据需要分配内存，而不必担心数据结构是否有空间进行存储。
   * 多道程序（能够同时运行多个程序，更好的利用机器资源）的出现强烈要求能够换出一些页，因为早期的机器显然不能将所有进程需要的所有内存页同时存放在内存中。
2. 为了使用硬盘上的交换页，我们需要引入一些新的机制，页表项中增加一个**存在位**来表示该页是否存在在物理内存中。
3. 当程序从内存中读取数据会发生什么？

### 第 22 章 超越物理内存：策略
1. 内存中只包含所有页的一个子集，所以可以将内存视为系统中虚拟内存页的缓存。
2. 常见策略：
* 最优策略（理想情况）：每次踢掉最远将来才会访问的页。
* FIFO：先进先出。不具有**栈特征**，增加缓存大小有可能命中率甚至下降。
* 随机：随机选择一个页面换出。
* LRU(最近最少使用) / LFU(最不经常使用)：利用历史信息来决定换出哪些页，一个是频率，如果一个页被访问了很多次，那么他不应该被换出；一个是近期性，越近被访问过的页，也许再次访问的可能性也就越大。

### 第 23 章 VAX/VMS虚拟内存系统
1. 页的按需置零（demand zeroing）：初级实现中，操作系统响应一个请求，在物理内存中找到页，将该页添加到堆中，并将其置零（否则你可以看到其他进程在使用这个页时的内容），然后将其映射到你的地址空间。利用按需置零，页加入地址空间时，os会在页表中放入一个标记页不可访问的条目，如果进程读取或写入页，会向os发送一个陷阱，此时os再进行置零，并且映射到进程的地址空间，从而减少开销，避免一些不会使用的页也进行按需置零。
2. 写时复制(copy on write)：如果os需要将一个页面从一个地址空间复制到另一个地址空间，不是实际复制它，而是将其映射到目标地址空间，并在两个地址空间中将其标记为只读，如果其中一个地址空间确实尝试写入页面，就会陷入os，os此时再分配一个新页面，填充数据。

## 第二部分 并发

### 第 26 章 并发：介绍

1. 线程：为当个运行进程提供的抽象。经典观点是一个程序只有一个执行点（一个ip寄存器，用来存放要执行的指令地址），但是多线程程序会有多个执行点（多个pc，每个都用于取指令和执行）。换一个角度看，每一个线程类似于独立的进程，只有一点区别：**线程之间共享地址空间，从而可以访问相同的数据。**每个线程有自己的一组用于计算的寄存器，所以在一个处理器上切换线程，就必须要保存相关信息。对于进程，我们将状态保存到进程控制块（PCB），而对于线程，我们需要一个或多个线程控制块（TCB）。但是，与进程相比，线程之间的上下文切换有一点主要区别：**地址空间保持不变（即不需要切换当前使用的页表）**，进程与线程之间的另一个主要区别在于栈，多线程程序中每一个线程都有一个栈。
2. 原子性：全部或没有。
3. 线程之间的交互：
* 访问共享变量：互斥，为临界区支持原子性。
* A线程需要在B线程执行完以后运行：同步。

### 第 27 章 插叙：线程API
1. 将 `void` 指针作为函数的参数，允许我们传入任何类型的参数；将 `void` 作为返回值，允许线程返回任何类型的结果。
2. `POSIX` 线程提供的锁的重要api：
```c
int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_unlock(pthread_mutex_t *mutex);
//所有的锁在使用的时候都必须正确初始化
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_init(&lock, NULL);
//用完锁进行摧毁
pthread_mutex_destroy();
```
3. **要使用条件变量，必须另外有一个与此条件相关的锁。**因为条件变量也是共享资源，是多个线程可能同时访问的东西，所以要加锁保证互斥。
```c
//调用线程进入休眠状态，等待其他线程发出信号。
int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);
//唤醒某个条件。
int pthread_cond_signal(pthread_cond_t *cond);
```

### 第 28 章 锁
1. 并发编程的基本问题：**原子式的执行一系列指令，但是由于单处理器的中断或者多个线程在多个处理器上并发执行，很难做到。**

2. 评价锁的指标：
* 互斥：能否实现互斥，即阻止多个线程进入临界区。
* 公平性：当锁可用的时候，是否每一个竞争线程有公平的机会抢到锁。
* 性能：使用锁以后增加的时间开销，需要考虑多种场景，如只有一个线程获取释放锁，一个cpu上多个线程竞争锁，多个cpu上多个线程竞争锁。

3. 锁的实现：
* **关闭中断**：为单处理器系统开发，在临界区关闭中断，这样就不会被其他线程进行抢占，从而实现原子操作。这种方法的弊端：
   * 对于开关中断这样的指令，应该是特权级的指令，一般的进程不应该有这个权限，否则很容易出现安全问题，若进程出现死循环，也只能重启系统。
   * 现在基本上都是多处理器，这种方式对多处理器不起作用，因为多处理器中关中断只能影响当前CPU核心，而其他核心仍然可以并行执行代码。多处理器上的并发问题不仅是中断导致的临界区操作不具有原子性，还包括多个线程可能在不同核心同时进入临界区，访问资源。
   * 关闭中断可能导致中断丢失，比如在中断关闭的过程中，磁盘 io 结束，发起的中断将不会被 cpu 响应，所以可能需要一些更复杂的机制来对中断进行保存。
   * 性能较差。
* **原子交换指令**：测试并设置指令（test-and-set instruction），也叫做原子交换指令（atomic exchange），通过标志位来实现锁：
   ```c
   1    typedef struct  lock_t { int flag; } lock_t;
   2
   3    void init(lock_t *mutex) {
   4        // 0 -> lock is available, 1 -> held
   5        mutex->flag = 0;
   6    }
   7
   8    void lock(lock_t *mutex) {
   9        while (mutex->flag == 1) // TEST the flag
   10           ; // spin-wait (do nothing)
   11       mutex->flag = 1;         // now SET it!
   12   }
   13
   14   void unlock(lock_t *mutex) {
   15       mutex->flag = 0;
   16   }
   ```
   但是需要硬件提供一定的支持，否则比如线程一调用 `lock` ，执行到 `while(mutex->flag == 1)` 以后，正准备执行 `mutex->flag = 1` 时，被切到线程二调用 `lock` ，然后再返回，这样就导致线程一二都可以进入临界区，所以硬件提供了一些指令，各个平台上有不同的指令(x86上为 xchg 指令)，这些指令干的事情可以概括如下：
   ```c
   1    int TestAndSet(int *old_ptr, int new) {
   2        int old = *old_ptr; // fetch old value at old_ptr
   3        *old_ptr = new;    // store 'new' into old_ptr
   4        return old;        // return the old value
   5    }
   ```
   测试并设置指令做了下述事情。它返回old_ptr指向的旧值，同时更新为new的新值。当然，关键是这些代码是原子地（atomically）执行。所以我们可以利用该指令来实现 **自旋锁**，仅仅需要将上面的代码修改为：
   ```c
      while(TestAndSet(&lock->flag, 1) == 1);
   ```
   **重点就是在于 `while` 判断的时候原子的进行了值的设置，而不会在对 `flag` 的值进行修改的时候被中断。**
* **比较并交换**：某些系统提供了另一个硬件原语，即比较并交换指令（x86上为 compare-and-exchange），指令伪代码:
   ```c
   1    int CompareAndSwap(int *ptr, int expected, int new) {
   2        int actual = *ptr;
   3        if (actual == expected)
   4            *ptr = new;
   5        return actual;
   6    }
   ```
   该指令会检测 `ptr` 指向的值与 `expected` 的值是否相等，如果相等，则更新 `ptr` 指向的值为新值，否则什么也不做，然后返回旧值。利用该指令，也可以实现一个锁：
   ```c
      while(CompareAndSwap(&lock->flag, 0, 1) == 1);
   ```
   如果 `lock->flag` 指向的值是0，则变为1，并返回0；否则，值是1，返回1。**重点就是在于 `while` 判断的时候原子的进行了值的设置，而不会在对 `flag` 的值进行修改的时候被中断。**
* **链接的加载和条件式存储指令**：例如Mips架构提供了链接的加载(load-linked)和条件式存储(store-conditional)可以配合使用来实现临界区。
   ```c
   1    int LoadLinked(int *ptr) {
   2        return *ptr;
   3    }
   4
   5    int StoreConditional(int *ptr, int value) {
   6        if (no one has updated *ptr since the LoadLinked to this address) {
   7            *ptr = value;
   8            return 1; // success!
   9        } else {
   10           return 0; // failed to update
   11       }
   12   }
   ```
   链接的加载指令从内存中取出一个值放入寄存器，条件式存储指令比较特殊，只有当上一次加载的地址没有被再调用过 `LoadLinked` 才会成功，将值进行修改，否则失败。依据这两条硬件指令，我们也可以实现一个锁：
   ```c
      void init(lock_t *mutex){
         mutex->flag = 0;
      }
      void lock(lock_t *mutex){
         while(1){
            while(LoadLinked(&mutex->flag) == 1);
            if(StoreConditional(&mutex->flag, 1) == 1)
               return;
         }
      }
      void unlock(lock_t *mutex){
         mutex->flag = 0;
      }
   ```
   **重点就是判断标志以后如何可以原子的进行修改**
* **获取并增加**：获取并增加指令(fetch-and-add)，可以原子的返回特定地址的旧值，然后让该值自增一。
   ```c
   1    int FetchAndAdd(int *ptr) {
   2        int old = *ptr;
   3        *ptr = old + 1;
   4        return old;
   5    }
   1    typedef struct  lock_t {
   2        int ticket;
   3        int turn;
   4    } lock_t;
   5
   6    void lock_init(lock_t *lock) {
   7        lock->ticket = 0;
   8        lock->turn   = 0;
   9    }
   10
   11   void lock(lock_t *lock) {
   12       int myturn = FetchAndAdd(&lock->ticket);
   13       while (lock->turn != myturn)
   14           ; // spin
   15   }
   16
   17   void unlock(lock_t *lock) {
   18       FetchAndAdd(&lock->turn);
   19   }
   ```
   相当于每一个线程有一个顺序，当你调用 `lock` 的时候，就会将当前的 `ticket` 赋值给你，然后每次解锁的时候就调用下一个，将 `turn + 1`，只有 `turn == ticket` 的时候，就轮到这个线程持有锁了。

4. 当有 N 个线程在单处理上运行的时候，如果需要一把锁，那么只有一个线程可以持有，然后时间片到了以后，调用别的线程去运行，别的线程只会去尝试获取锁，造成 `cpu` 空转，如果这 `N` 个线程都被调用一次，那么就会浪费 `N - 1` 个时间片，极大的造成性能的浪费。

5. 提高自选锁的性能的方法:
* 主动让出CPU：操作系统提供一种原语，当线程发现自己要进行自旋的时候，主动调用该原语，os 就将该线程从运行态变为就绪态，从而允许其他线程进行运行。（但是上下文切换依然开销很大，而且有可能会有进程饿死，一直得不到调用）
* 使用队列，用休眠替代自旋：为了避免资源浪费以及进程饿死的出现，所以我们应该对**唤醒进程进行显式的控制**，操作系统应该有权力来决定哪一个进程得到锁，Solaris提供了两个系统调用：
   * park()：让调用线程进行休眠。
   * unpark(threadId)：唤醒 threadID 标识的线程。
   Linux 下提供了两个系统调用：
   * futex_wait(address, expected)：如果 address 处的值等于 expected，就会让调用线程睡眠，否则，调用立刻返回。
   * futex_wake(address)：唤醒等待队列中的一个线程。


### 第 29 章 基于锁的并发数据结构
1. 通过给数据结构加锁可以使得数据结构**线程安全(thread safe)**。
2. 最简单、最基本的并发数据结构常见的数据模式：加一把锁，在调用函数操作该数据结构时获取锁，从调用返回时释放锁。**如果简单的方法可以正常工作，就不需要精巧的设计。**
3. 并发计数器的设计：通过对计数器递增递减来加锁可以实现正确性，但是性能较差。所以使用一种**懒惰计数器**，对于每一个 CPU，有一个局部计数器，还有一个全局的计数器，每一个计数器都由一把锁来控制，每个线程运行在 CPU 上的时候，可以更新局部计数器，然后在特定的时间间隔以后，再将局部计数器的值同步到全局计数器。时间间隔比较短的时候，性能较差，但是全局与局部差异较小，时间间隔长的时候，性能较好，但是全局与局部差异较大。
4. 并发链表：可以给链表加一把大锁，要操作链表的时候尝试获取锁。可以缩小锁的粒度（即临界区越短越好），比如在给链表插入节点的时候，只需要执行插入操作之前获取锁。
5. **在编码的时候，注意控制流的变化导致函数返回和退出，或者一些错误情况导致函数停止执行，因为很多函数会在开始的时候获取锁、分配内存，或者进行其他一些改变状态的操作，如果错误发生，代码需要在返回前恢复各种状态。**

### 第 30 章 条件变量
1. 互斥并不是并发编程唯一需要的原语，互斥只能保证某几个操作之间是独立的，即 A 发生的时候 B 不会发生， B 发生的时候 A 不会发生，但是很多情况下，线程之间还需要 **同步**，即线程之间发生的先后顺序需要被控制，比如 A 先发生， B 再发生，最简单的情况是利用一个**共享变量**，一个线程不断地去判断这个共享变量的值是否被修改，若被修改，则证明另一个线程执行完毕，但是这样子等待的线程会一直自旋，浪费 CPU 性能，最好的方式是让在等待的时候线程休眠，然后另一个线程执行完毕以后，再对等待的线程进行唤醒。
2. 条件变量：是一个显式队列，当某些执行状态不满足的时候（条件不满足），线程把自己加入队列，等待该条件；当另外某个线程改变了上述状态以后，就可以唤醒一个或多个等待线程，让他们继续执行。
   * wait()：线程睡眠
   * signal()：唤醒等待在某个条件变量上的睡眠线程。
3. 条件变量也是一个共享内存（临界区），多个线程都会对其进行读写，所以需要给其加锁。（hold the lock when calling signal or wait）
4. 生产者/消费者（有界缓冲区）问题：
   * 使用while而不是if：发送信号唤醒线程**只是暗示状态发生了变化，并不会保证就是线程想要的状态**，这是很多系统上信号的语义（Mesa语义），还有一种语义（Hoare）是保证唤醒线程会立刻执行，这种语义下if则不会有问题，但是这种语义实现比较复杂，几乎所有系统采用了Mesa语义。
   * 不能只使用一个条件变量：因为发送信号唤醒线程，具体唤醒哪一个线程取决于等待队列的管理，假设有两个消费线程因为缓冲区为空进行休眠，此时一个生产线程在缓冲区放了东西，然后再放的时候发现缓冲区有东西，所以休眠，此时消费线程1消费缓冲区，然后唤醒了消费线程2，此时消费线程2发现缓冲区没有东西，进行休眠，然后消费线程1执行发现没有东西，休眠，所以此时一个生产线程，两个消费线程都会进行休眠。**信号需要具有指向性。**

5. 覆盖条件：有的时候发送信号唤醒线程的时候，线程被唤醒检查条件发现条件依然不满足，从而继续休眠，但是有些等待的线程条件是满足的，从而就浪费了这一次的唤醒，所以有一种处理方式就是**唤醒所有线程**。


### 第 31 章 信号量
1. 在并发编程中，**同步原语**用于协调多个线程或进程对共享资源进行访问：
   * 控制并发访问：锁，实现互斥
   * 线程间通信：条件变量

   可以使用**信号量**来实现锁和条件变量，换言之，信号量可以作为与同步有关所有工作的单一原语。

2. 信号量有两个关键操作:
   * sem_wait()：信号量的值减少 1，如果信号量的值 < 0 则挂起调用线程。
   * sem_post()：信号量的值增加 1，如果此时有线程等待，则唤醒一个线程。
   **所以当信号量的值为负数的时候，这个值就是等待线程的个数。**

3. 二值信号量（锁）：将信号量的值设置为 1，此时访问临界区的时候调用 `sem_wait()`，出临界区以后调用 `sem_post()` 就可以实现锁的效果。

4. 使用信号量作为条件变量：将信号量的值设置为 0， A 等待 B 执行完成后再执行，那么就可以在 A 中调用 `sem_wait()`，然后在 `B` 中调用 `sem_post()` 。

5. 使用信号量解决生产者/消费者问题：
   * 缓冲区是共享资源，对于缓冲区的操作需要加锁保持原子性。
   * 对于锁的获取，应该是先等待条件变量，条件满足以后再尝试获取锁，如果先获取锁则可能出现死锁。

6. 读者-写者锁：不同的数据结构访问模式可能需要不同类型的锁，比如一个并发链表如果插入节点则需要加锁，但是如果只是读取节点的值，则没必要加锁。
   ```c
   typedef struct _rw_lock_t{
      sem_t lock; //普通的锁，值为 1
      sem_t writelock; // 用于允许一个人写或多个人读
      int readers; //当前在临界区读的个数
   } rwlock_t;
   ```
   写锁与普通的锁一致，但是对于获取读锁时，我们首先获取 lock，然后增加 readers 的数量，如果是第一位读者，同时获取 writelock，然后就可以释放 lock 了；释放读锁的时候，首先获取 lock，然后减少 readers 的数量，如果是最后一位读者，释放 writelock。**此处的 lock 相当于在控制对 readers 的读写，保证其更新是原子的。** 

7. 哲学家就餐问题：打破依赖！！！如果每个人都优先拿左边的叉子，那么可能会出现死锁，我们可以让某个人优先拿自己右手的叉子。

8. 实现信号量：初始化，wait，post
   ```c
   typedef struct _Zem_t{
      int value;
      pthread_cond_t cond;
      pthread_mutex_t lock;
   } Zem_t;
   
   //init
   void Zem_init(Zem_t *s, int value){
      s->value = value;
      Cond_init(&s->cond);
      Mutex_init(&s->lock);
   }
   
   //wait
   void Zem_wait(Zem_t *s){
      Mutex_lock(&s->lock);
      while(s->value <= 0)
         Cond_wait(&s->cond, &s->lock);
      s->value--;
      Mutex_unlock(&s->lock);
   }
   
   //post
   void Zem_post(Zem_t *s){
      Mutex_lock(&s->lock);
      s->value++;
      Cond_signal(&s->cond);
      Mutex_unlock(&s->lock);
   }
   ```
   与上面描述的信号量有点差别，这里的信号量永远不会小于0。

### 第 32 章 常见并发问题
1. 违反原子性缺陷：违反了多次内存访问中**预期的可串行性**，即代码段本意是原子性的，但是在执行过程中并没有强制实现原子性。没有互斥。

2. 违反顺序缺陷：两个内存访问的预期顺序被打破了。没有同步。

3. 产生死锁的四个条件（必要条件）：
   * 互斥：线程对于需要的资源进行互斥的访问。
   * 持有并等待：线程持有了资源，同时又在等待其他资源。
   * 非抢占：线程已经获得的资源不能被其他线程进行抢占。
   * 循环等待：线程之间存在一个环路，环路上每个线程都额外持有一个资源，而这个资源又是下一个线程要申请的。
   要避免死锁，就可以打破以上的任意一个条件。

4. 实际代码中，最常采用的就是让代码不会产生循环等待：
   * 锁的全序：每次都是先申请 A ，再申请 B。
   * 锁的偏序：

5. 在获取多个锁的时候，可以通过锁的地址顺序来获取锁，从而可以避免循环等待。

### 第 33 章 基于事件的并发（进阶）
1. 基于事件的并发：当使用多线程实现并发的时候，一方面很容易忘记加锁、死锁等问题出现，即很难实现正确并发；另一方面，开发者无法控制多线程在某一时刻的调度，程序员创建线程以后就依赖于操作系统的调度。所以有基于事件的并发，即不用线程，同时保证对并发的控制。

2. 事件循环：等待某件事件发生，当它发生时，检查事件类型，然后做少量的工作。
   ```c
   while(1){
      events = getEvents();
      for(e in events)
         processEvent(e);
   }
   ```
   处理程序在处理一个事件的时候，是系统中发生的唯一活动。

3. select()/poll()：检查是否有任何应该关注的进入 I\O。select()检查I/O描述符集合，它们的地址通过readfds、writefds和errorfds传入，分别查看它们中的某些描述符是否已准备好读取，是否准备好写入，或有异常情况待处理。在每个集合中检查前nfds个描述符，即检查描述符集合中从0到nfds-1的描述符。返回时，select()用给定请求操作准备好的描述符组成的子集替换给定的描述符集合。select()返回所有集合中就绪描述符的总数。

## 第三部分 持久性

### 第 36 章 I/O 设备
1. 操作系统检查设备状态的时候如何避免频繁轮询，从而降低管理设备的 CPU 开销？
   * 利用中断：CPU 不再需要轮询设备，而是向设备发送一个请求，然后就可以让对应进程睡眠，切换执行其他任务，当设备完成了自身操作，会抛出一个硬件中断，引发 CPU 跳转到执行操作系统中预先定义好的中断服务程序。
   * 利用 DMA 进行更高效的数据传送：如果 CPU 参与数据移动，即位编程 I/O(programmed I/O, PIO)，这种方式会将 CPU 的时间浪费在向设备传输数据或从设备传出数据的过程中，所以可以**分离这项工作**，提高 CPU 利用率，即 DMA 技术，直接内存访问。

2. 操作系统与设备之间通信：
   * 使用明确的 I/O 指令，这些指令规定了操作系统将数据发送到特定设备寄存器的方法。
   * 内存映射 I/O，硬件将设备寄存器作为内存地址提供，当需要访问设备的时候，操作系统独读取或者写入到该内存地址，然后应将会将读取/写入转移到设备上。

### 第 37 章 磁盘驱动器
1. 磁盘驱动器由大量扇区（512个字节）组成，每个扇区都可以读取或写入，在具有 n 个扇区的磁盘驱动器上，扇区从 0 到 n -1 进行编号。许多文件系统都会多扇区操作，即一次写入或者读取多个扇区（常见的为 4 KB = 2 ^ 12 个字节 = 8个扇区），**但是驱动器制造商唯一保证的是单个 512 个字节的写入是原子的，即要么完成要么不做。**所以如果有的时候掉电，则只能完成较大写入的一部分。

2. 磁盘的基本几何形状：
   * 盘片：一个圆形坚硬的表面，磁盘可能由一个或多个盘片，每个盘片有两面，每一面都称为表面。
   * 所有盘片围绕主轴连接在一起，主轴以一个恒定的速度旋转盘片。
   * 磁道：数据在扇区的同心圆的每个表面上被编码，称这样的同心圆为一个磁道。
   * 读写磁盘由磁头完成，驱动器的每个表面山都有一个磁头，磁头连接到单个磁盘臂上，磁盘臂在表面上移动，将磁头定位在期望的磁道上。

3. 驱动器访问给定的扇区：
   * 寻道过程：将磁盘臂移动到正确的磁道。（一圈圈的同心圆）
   * 旋转过程：等待待访问的扇区旋转到磁头下方。

4. 任何现代磁盘驱动器都有一个重要组成部分，即**缓存，也称作磁道缓冲区**。该缓存只是少量的内存，驱动器利用这些内存来保存从磁盘读取或写入磁盘的数据。例如：从磁盘读取山区的时候，驱动器可能会将该磁道上所有扇区都进行缓存的时候，写入磁盘的时候，驱动器有两种选择：
   * 后写缓存 write back：写入内存，回报完成写入。
   * 直写 write through：写入磁盘，回报完成写入。

5. I/O 时间：
   $$T_{I/O} = T_{寻道} + T_{旋转} + T_{传输}$$
   $$R_{I/O} = \frac{大小_{传输}}{T_{I/O}}$$

6. 磁盘调度：电梯算法（SCAN或C-SCAN），以跨越磁道的顺序来服务磁盘请求。从内圈磁道到外圈，再从外圈到内圈，一直重复。

### 第 38 章 廉价冗余磁盘阵列（RAID）
1. * RAID 0级：条带化，没有冗余。一个 RAID 包含很多块，条带化的意思就是将每个块按照顺序放在不同的磁盘上，比如有四个磁盘，那么块0在磁盘0，块1在磁盘1，块2在磁盘2，块3在磁盘3，块4在磁盘0，以此类推。
   * RAID 1级：镜像，有冗余。生成系统中每个块的多个副本，每个副本存储在不同的磁盘上，可以容许磁盘故障。
   * RAID 4级：通过奇偶校验节省空间，对于每一条数据，添加一个奇偶校验块，用于存储该条块的冗余信息。
   * RAID 5级：旋转就校验，解决**小写入**问题，即在 4 级的时候，即使对不同的磁盘中的块进行更新，也需要更新奇偶校验块，而奇偶校验块处于一个磁盘中，这个磁盘不能并行读。

### 第 39 章 插叙：文件和目录
1. 存储虚拟化形成了两个关键的抽象：
   * 文件：文件就是一个线性字节数组，每个字节都可以读取或写入。**每个文件都有某种低级名称，在unix世界中是 `inode` 号**。
   * 目录：目录也是一个文件，有一个 `inode` 号与其关联，但区别是文件中的结构很多（文本文件、图片、音频...），但是目录的内容非常具体，**它包含一个（用户可读名字， 低级名称）对的列表**。

2. 文件系统接口：
   * 创建文件： `open` 系统调用。返回一个文件描述符（file descriptor），文件描述符是一个整数，用于标识文件，可以理解为一个指向文件类型对象的指针。
   * 以偏移量的方式打开文件： `lseek` 系统调用。对于每个进程打开的文件，操作系统都会跟踪一个 "当前偏移量"，这将会决定下一次读取或写入的开始位置。（也就是文件描述符自带偏移量，当发生 N 个字节的读或写的时候，N 被隐式添加到当前偏移）
   * 写入文件： `write` 系统调用，它只是告诉文件系统，在将来的某个时刻，将数据写入持久存储；但是对于有些应用，需要保证一定写入了磁盘，在 UNIX 中提供了 `fsync(int fd)` 系统调用，它可以保证将要写入这个文件描述符的所有内容全部写入磁盘以后，该系统调用才会返回。往往也需要对文件的目录使用该系统调用，这样能保证如果文件是新创建的，不仅在磁盘上，也是目录的一部分。
   * 文件重命名：`rename` 系统调用。原子操作，不论系统是否崩溃，文件名称要么是旧名称，要么是新名称。
   * 获取文件信息：`stat()` `fstat()` 系统调用，查看文件的元数据。
   * 删除文件：`unlink` 系统调用。

3. `strace` ：跟踪程序在运行时所做的每个系统调用。

4. 硬链接：`link` 系统调用，可以将一个新的文件名“链接”到一个旧的文件名，即文件的两个高级名称指向同一个低级名称（inode号）。

5. 创建文件：在 UNIX 系统中，创建文件实际上做了两件事。
   * 构建一个 `inode`，跟踪几乎所有关于文件的信息，包括大小、文件块在磁盘上的位置等等。
   * 将人类可读的名称链接到该文件，并且将该链接放入目录中。

6. 删除文件：调用 `unlink` 系统调用取消该文件名与 `inode` 的链接，如果 `inode` 中的引用计数达到0，则会在文件系统中释放 `inode` 和相关数据块，真正删除文件。

7. 符号链接：也被称为软链接。因为硬链接有局限：
   * 不能创建目录的硬链接，dir1 下面创建 subdir1，然后再 subdir1 下面创建 subdir1 的硬链接 link_to_parent，则会出现 dir1/subdir1/link_to_parent->dir1/subdir1->dir1/subdir1/link_to_parent，无限循环。
   * 不能链接到其他磁盘分区中的文件，因为 `inode` 号在特定的文件系统中是唯一的，不能跨文件系统。

   所以出现了 `symbolic link`，它是一个文件，将链接指向的文件的路径名作为链接文件的数据。

8. 如何从许多底层文件系统组建完整的目录树？
   * 通过 `mkfs` 创建一个文件系统，给该工具提供一个设备（如磁盘分区/dev/sda1），一种文件系统类型(如ext3)，然后该工具就会在设备上写入一个空文件系统，**从根目录开始**。
   * 创建了文件系统以后，通过 `mount` 程序来进行挂载，以现有目录作为目标挂载点，本质上是将新的文件系统粘贴到目录树的这个点上。

### 第 40 章 文件系统实现
1. 文件系统是纯软件。考虑文件系统以下两个方面：
      * 文件系统的数据结构：文件系统在磁盘上使用哪些类型的结构来组织其数据和元数据。
      * 文件系统的访问方法：如何将进程发出的调用，映射到它的结构上？在执行系统调用的时候，读取哪些结构？改写哪些？等等。

2. 文件系统中，通常除了用户数据以外，其他数据都称为 `metadata` 元数据。即文件创建时间、修改时间、大小、权限等信息。

3. 文件系统在磁盘上的数据结构的整体组织：
      * 将磁盘分成块，比如每个块 4 KB，这样磁盘就变成了元素为块的数组，比如有 N 个块，就可以通过 0 ~ N-1 进行索引。
      * 磁盘中的一些块用于存放用户数据。
      * 磁盘中的一些块用于存放元数据，通过 `inode` 结构来进行组织，所以一些块用于存放 `inode` 。
      * 要有一些数据结构用来记录哪些 `inode` 还没有使用，哪些使用；数据块中哪些被使用，哪些还没有使用。
      * 还需要有一个超级块，来记录哪些块是用来存放 `inode`，哪些块是用来存放用户数据的，哪些块是存放使用信息的。

4. 文件系统中最重要的磁盘结构之一是 `inode` ，每一个 `inode` 通过一个数字 `inumber` 隐式引用。`inode` 数据结构中最重要的字段就是一个指向对应文件数据块的指针，一般会有一些直接指针（文件较小的情况下）和一个间接指针：
      * 直接指针：直接指向数据块的指针，在现在的系统中一般有 12 个。
      * 间接指针：指向一个存放指向数据块指针的指针表的块（二级，可以有多级），比如 12 个直接指针，1 个间接指针，磁盘地址 4 个字节，一个块是 4 KB，那么就最大可以指向 $$ (12 + \frac{2 ^ {12}(4 KB)}{4}) \times 4 = 4144 KB$$

5. 文件系统在实现目录的时候，一个目录基本上只包含一个二元组（条目名称， inode 号）的列表：
   * inumber号：表示文件的 `inode` 号，用于查找文件的元数据。
   * 记录长度：文件名称的总字节数加上所有的剩余空间。
   * 文件名称长度：文件名称的长度
   * 文件名称：文件名称。
   其中记录长度是用来读取目录下一个条目的，比如拿到第一个条目的地址，在它的基础上加上记录长度，就可以拿到第二个条目的地址；除此以外，如果记录长度大于名称长度，那么就说明目录的两个条目之间存在空闲空间，那么有新条目加入目录的时候，就可以使用这些空间。

6. 在上面的模型中，理解读取写入文件的过程：
   * 从磁盘读取文件：要读取文件，则必须拿到文件的块的地址，也就是必须通过 `inode` 结构拿到指针，所以我们需要拿到 `inode` 节点。所以我们就要从这个文件的父目录中拿到 `inode` 号，一步步找上去，就变成了要拿到根目录 `/` 的 `inode` 号，在系统中，根的 `inode` 号是2，是已知的。所以此时就可以一步步往下找，知道找到文件的 `inode` 号，然后再去找到文件的数据块，进行文件读取。**所以在读取文件的过程中，会发生多次读取，从根目录一直找到文件，最后还需要写入文件的 `inode` 结构，来更新文件的最终写入时间。**
   * 写入磁盘：写入文件到磁盘与从磁盘中读取文件的过程类似，先从根目录拿到对应要写的文件，只不过在写入文件的时候，可能需要新的数据块的分配，那么这个时候就需要：
      * 读取数据块位图，来更新某个数据块已经分配。
      * 读取 inode 结构，来更新数据块指针、文件大小等一些元数据信息。
      * 写入数据块。
      
      如果文件不存在，也就是创建一个新文件，那么还需要：
      * 分配一个 inode 结构，需要读写 inode 结构，那么此时就需要读取 inode 位图，来找到哪一个 inode 号还没有被使用，并且标记为使用。
      * 还需要在该文件的目录条目中增加这个文件的条目，如果目录占的数据块满了，那么还需要给目录分配新的数据块。

7. 考虑到从磁盘中读写文件的时候有多次 I/O，所以大多数文件系统积极使用系统内存(DRAM)来缓存重要的块。
   * 读缓存：比如在读取的时候，将这个目录的 inode 节点存入缓存，那么后续在这个目录下读写就会变快。
   * 写缓存：延迟写入，把一些写入更新变成一批写入，比如创建某个文件，则需要更新位图，后面又创建了某个文件，则可以把这两次对于位图的写入变成一次，从而减少 I/O 次数。
   
   但是对于一些对于持久化要求比较高的程序，则必须强制写入磁盘：
   * fsync 系统调用
   * 使用绕过缓存的直接 I/O 接口
   * 使用原始磁盘接口并完全避免使用文件系统

### 第 41 章 局部性和快速文件系统
1. 文件系统需要提供的基本抽象：**文件和目录层次结构。**

2. 为了提高磁盘访问的性能，在磁盘上放置文件和目录以及相关的元数据时，有一个基本策略：**相关的东西放在一起。**对于 FFS(快速文件系统)则采用了以下策略：
   * 目录：找到分配数量少的柱面组（希望跨组平衡目录）和大量的free inode（希望后面分配一堆文件），然后将目录数据和 inode 放在这个分组中。
   * 文件：一般情况下，将文件的数据块分配到其 inode 相同的柱面组中，从而防止 inode 和数据之间的长时间寻道；其次，它将位于同一目录中的所有文件，放在它们所在目录的柱面组。（因为目录中的文件大概率一起访问）

### 第 42 章 崩溃一致性：FSCK 和 日志
1. 文件系统不同于一般的数据结构，它需要持久，所以需要存放在磁盘中，但是一次写入意味着需要更改很多数据结构，比如：inode 结构，数据块等等，但是磁盘同一时间只能提供一个服务，那么当出现断电、系统崩溃等情况时，就需要一些策略来保持数据的一致性，比如修改了数据块，还没来得及修改 inode 结构，出现了系统崩溃，那么恢复以后如何来保证数据的一致性？

2. 解决方案一：文件系统检查程序 
早期的文件系统采用简单的方式来处理崩溃一致性问题，即允许不一致出现，然后进行修复，比如 `fsck` (file system checker) 工具，它会检查磁盘上的数据，从而让文件系统内部的数据结构保持一致：
   * 只能处理文件系统内部数据结构不一致的问题，但比如在文件中添加内容的时候，更新了 inode 节点数据，更新了位图数据，还没有更新数据块，此时崩溃，那么文件系统内部的数据结构是一致的，只是数据块中的内容是脏数据，这种情况 `fsck` 无法处理。
   * 比较慢，需要扫面整个磁盘来处理，且实现起来很复杂，需要大量的文件系统知识。

3. 解决方案二：日志（或预写日志）
基本思路是在更新磁盘时，在覆写结构之前，首先在磁盘的其他位置描述你将要做的事情。此时如果在覆写结构时发生崩溃，就可以返回并且查看之前的日志，然后重试。
   * 日志写入：将事务内容（TxB 元数据 数据）写入日志。
   * 日志提交：将事务提交块（TxE）写入日志，等待写完成。
   * 加检查点：将待处理的元数据和数据更新写入到文件系统的最终位置。
更新文件系统磁盘结构的基本协议：
   * 文件系统缓冲内存中的更新一段时间。（为了进行批处理，从而避免对磁盘的过多写入）
   * 将事务的详细信息写入日志。
   * 事务完成以后，文件系统会加检查点，将这些块写入磁盘上的最终位置。
为了进一步减少磁盘的冗余写入，在日志中只写元数据，而不写入数据块（称为顺序日志），但是这种方式一定要注意数据块写入的时机，如果数据块后面写入，那么即使重新执行日志中的事务，也只能保证元数据块中的数据结构是一致的，但是 inode 指向的数据块中存放的是脏数据，所以**通过强制先写入数据，文件系统可以保证指针永远不会指向垃圾**。


### 第 43 章 日志结构文件系统
1. 写入磁盘时，LFS（Log-structured File System）首先将所有更新缓存在内存段中，当段已满时，它会在一次长时间的顺序传输中写入磁盘，并传输到磁盘的未使用部分。

2. 按顺序写入磁盘：当用户写入数据块时，不仅是数据被写入磁盘，还有其他需要更新的元数据。

### 第 44 章 数据完整性和保护
1. 确保放入存储系统的数据和存储系统返回的数据是一致的。

### 第 47 章 分布式系统
1. 现代网络的核心原则：**通信基本是不可靠的。**

2. 对于一个分布式系统而言，最基本的方面就是通信，也就是说不同的机器之间应该如何通信，我们应当如何在通信层制定一些协议，来应对不可靠的通信环境。

3. 在构建分布式系统时，编程语言抽象相比操作系统抽象有意义的多，最主要的抽象就是基于远程过程调用（Remote Procedure Call），即 RPC。RPC 都有一个简单的目标：**使得在远程机器上执行代码的过程像调用本地函数一样简单直接。** RPC 系统通常由两部分：
   * 存根生成器（stub generator）：有时也成为协议编译器（protocol compiler），通过自动化，消除将函数参数和结果打包成消息的痛苦。这种编译器的输入就是服务器希望导出到客户端的一组调用，然后生成一些不同的代码片段。
   * 运行时库（runtime library）：处理 RPC 系统中的大部分繁重工作。

### 第 48 章 Sun的网络文件系统（NFS）
1. 客户端/服务器架构，一台文件服务器，多台客户端，通过网络连接到服务器上，在客户端进行文件操作是透明的，通过网络将实际的操作发送给服务器，服务器解析以后进行相应操作，从磁盘中读取相应内容以后返回给客户端。

2. 在 NFS 的设计中，**每个客户端操作都包含完成请求所需要的全部信息**，也就是说客户端和服务器之间不会共享状态（比如文件描述符），这样当任意一方发生崩溃的时候，恢复起来都很容易。

3. 幂等性指的是一个操作执行一次和执行多次的效果是一样的，这样当这种操作失败的时候，只需要简单的重试就可以了。

### 第 49 章 Andrew文件系统（AFS）
1. 所有 AFS 版本的基本原则之一，就是在访问文件的客户端计算机的本地磁盘上，进行全文件的缓存。当 open 文件的时候，将从服务器获取整个文件，并存储到本地的磁盘上面，后续的 read 和 write 都被重定向到存储文件的本地文件系统。最后在 close 文件的时候，如果文件被修改则写回服务器。

2. NFS 是基于块的协议，也就是只会从服务器中读取或写入某些字节；AFS 每次都会读取整个文件内容。

### 附录B 虚拟机监视器
1. 虚拟机监视器（Virtual Machine Monitor， VMM）给 OS 提供假象，在 OS 之下控制硬件，但是让 OS 觉得是自己在控制硬件。（VMWare）